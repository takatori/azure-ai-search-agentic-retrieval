{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import textwrap\n",
    "import time\n",
    "from pathlib import Path\n",
    "from math import ceil\n",
    "\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIVectorizerParameters,\n",
    "    FieldMapping,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    IndexingParameters,\n",
    "    InputFieldMappingEntry,\n",
    "    LexicalAnalyzerName,\n",
    "    OutputFieldMappingEntry,\n",
    "    SearchField,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerDataSourceType,\n",
    "    SearchIndexerSkillset,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "\n",
    ")\n",
    "from azure.search.documents.models import QueryType, VectorizableTextQuery\n",
    "from azure.storage.blob import BlobServiceClient, ContentSettings\n",
    "from tqdm import tqdm\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.aio import SearchClient as AsyncSearchClinet\n",
    "from azure.search.documents.indexes.models import SearchIndexKnowledgeSource, SearchIndexKnowledgeSourceParameters, KnowledgeAgentOutputConfiguration, KnowledgeAgentOutputConfigurationModality, KnowledgeAgent, KnowledgeAgentAzureOpenAIModel, KnowledgeSourceReference\n",
    "from azure.search.documents.agent import KnowledgeAgentRetrievalClient\n",
    "from azure.search.documents.agent.models import KnowledgeAgentRetrievalRequest, KnowledgeAgentMessage, KnowledgeAgentMessageTextContent, SearchIndexKnowledgeSourceParams\n",
    "\n",
    "import datasets as ds\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(\n",
    "    credential, \"https://search.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# „Å©„ÅÆ split „Çí‰Ωø„ÅÜ„Åã\n",
    "SPLIT = \"test\"  # \"validation\" „ÇÇÂèØ\n",
    "MAX_SAMPLES = 300  # None „ÅßÂÖ®‰ª∂\n",
    "CHUNK_SIZE = 700\n",
    "CHUNK_OVERLAP = 200\n",
    "USE_ORIGINAL = False\n",
    "\n",
    "SEARCH_ENDPOINT = os.getenv(\"SEARCH_ENDPOINT\")\n",
    "AOAI_ENDPOINT = os.getenv(\"AOAI_ENDPOINT\")\n",
    "AZURE_STORAGE_CONNECTION_STRING = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "AZURE_AI_FOUNDRY_PROJECT_ENDPOINT = os.getenv(\"AZURE_AI_FOUNDRY_PROJECT_ENDPOINT\")\n",
    "\n",
    "AOAI_EMBEDDING_MODEL = \"text-embedding-3-large\"\n",
    "AOAI_EMBEDDING_DEPLOYMENT = \"text-embedding-3-large\"\n",
    "AOAI_GPT_MODEL = \"gpt-5-mini\"\n",
    "AOAI_GPT_DEPLOYMENT = \"gpt-5-mini\"\n",
    "\n",
    "AGENT_MODEL = \"gpt-5-mini\"\n",
    "AGENT_NAME = \"jqara-agent\"\n",
    "\n",
    "INDEX_NAME = \"jqara-index\"\n",
    "KNOWLEDGE_SOURCE_NAME = \"jqara-knowledge-source\"\n",
    "KNOWLEDGE_AGENT_NAME = \"jqara-knowledge-agent\"\n",
    "SEARCH_API_VERSION = \"2025-08-01-preview\"\n",
    "DATA_SOURCE_NAME = \"ds-jqara-chunks\"\n",
    "SKILLSET_NAME = \"ss-jqara-embed\"\n",
    "INDEXER_NAME = \"idx-jqara\"\n",
    "DIM = 3072\n",
    "BLOB_CONTAINER = \"jqara-docs\"\n",
    "BLOB_PREFIX = \"docs\"\n",
    "TOPK_LIST = [1, 3, 5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‰øùÂ≠òÂÖà„Éá„Ç£„É¨„ÇØ„Éà„É™„ÇíÊåáÂÆö\n",
    "local_dir = Path(\"datasets/JQaRA\")\n",
    "local_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Êó¢„Å´„É≠„Éº„Ç´„É´„Å´‰øùÂ≠òÊ∏à„Åø„Å™„Çâ„Åù„Çå„ÇíË™≠„ÅøËæº„ÇÄ\n",
    "if (local_dir / \"dataset_info.json\").exists():\n",
    "    print(\"üîÅ Loading dataset from local disk...\")\n",
    "    dataset = ds.load_from_disk(str(local_dir))\n",
    "else:\n",
    "    print(\"‚¨áÔ∏è Downloading dataset from Hugging Face Hub...\")\n",
    "    dataset = ds.load_dataset(\n",
    "        path=\"hotchpotch/JQaRA\",\n",
    "        trust_remote_code=True,\n",
    "        storage_options={\n",
    "            \"client_kwargs\": {\"timeout\": aiohttp.ClientTimeout(total=36000)}\n",
    "        },\n",
    "    )\n",
    "    dataset.save_to_disk(str(local_dir))\n",
    "    print(f\"üíæ Dataset saved locally to {local_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_data = dataset[\"dev\"]\n",
    "test_data = dataset[SPLIT]\n",
    "df =pd.DataFrame(test_data).head()\n",
    "json_str = json.dumps(df.to_dict(orient=\"records\"), ensure_ascii=False, indent=2)\n",
    "print(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_id(raw_id: str) -> str:\n",
    "    # Ë®±ÂèØÊñáÂ≠ó‰ª•Â§ñ„Çí \"_\" „Å´ÁΩÆ„ÅçÊèõ„Åà\n",
    "    return re.sub(r\"[^A-Za-z0-9_-]\", \"_\", raw_id)\n",
    "\n",
    "# id, text, title „Å†„ÅëÊäΩÂá∫„Åó„Å¶ JSON/JSONL „Å´Â§âÊèõ„Éª‰øùÂ≠ò\n",
    "columns_to_keep = [\"id\", \"text\", \"title\"]\n",
    "\n",
    "subset = test_data.select_columns(columns_to_keep)\n",
    "\n",
    "docs = [\n",
    "    {\n",
    "        \"id\": normalize_id(row[\"id\"]),\n",
    "        \"raw_id\": row[\"id\"],\n",
    "        \"text\": row[\"text\"],\n",
    "        \"title\": row[\"title\"],\n",
    "    }\n",
    "    for row in subset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsc = BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)\n",
    "container_client = bsc.get_container_client(BLOB_CONTAINER)\n",
    "try:\n",
    "    container_client.create_container()\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chunked(iterable, n):\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i:i+n]\n",
    "\n",
    "def upload_ndjson_batches(docs, prefix=BLOB_PREFIX, batch_size=10_000):\n",
    "    total = 0\n",
    "    for i, batch in enumerate(chunked(docs, batch_size)):\n",
    "        # 1Ë°å1„Éâ„Ç≠„É•„É°„É≥„Éà„ÅÆNDJSON\n",
    "        payload = \"\\n\".join(json.dumps(d, ensure_ascii=False) for d in batch).encode(\"utf-8\")\n",
    "        name = f\"{prefix}/batch_{i:06d}.jsonl\"\n",
    "        container_client.upload_blob(\n",
    "            name,\n",
    "            payload,\n",
    "            overwrite=True,\n",
    "            content_settings=ContentSettings(content_type=\"application/x-ndjson\"),\n",
    "        )\n",
    "        total += len(batch)\n",
    "    return total\n",
    "\n",
    "print(\"Uploaded:\", upload_ndjson_batches(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Client„Çí‰ΩúÊàê„Åô„Çã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_client = SearchIndexClient(\n",
    "    endpoint=SEARCH_ENDPOINT, \n",
    "    credential=credential\n",
    ")\n",
    "\n",
    "indexer_client = SearchIndexerClient(\n",
    "    endpoint=SEARCH_ENDPOINT, \n",
    "    credential=credential,\n",
    ")\n",
    "\n",
    "print(f\"{SEARCH_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# „Éá„Éº„Çø„ÇΩ„Éº„Çπ„Çí‰ΩúÊàê„Åô„Çã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = SearchIndexerDataContainer(\n",
    "    name=BLOB_CONTAINER,\n",
    "    query=BLOB_PREFIX,  # \"docs\" ‰ª•‰∏ã„Å†„ÅëÂèñ„ÇäËæº„ÇÄ„ÄÇ„Ç≥„É≥„ÉÜ„ÉäÂÖ®‰Ωì„Å™„Çâ None\n",
    ")\n",
    "\n",
    "data_source = SearchIndexerDataSourceConnection(\n",
    "    name=DATA_SOURCE_NAME,\n",
    "    type=SearchIndexerDataSourceType.AZURE_BLOB,\n",
    "    connection_string=AZURE_STORAGE_CONNECTION_STRING,\n",
    "    container=container,\n",
    "    description=\"JQaRA JSONs in Blob Storage\",\n",
    ")\n",
    "\n",
    "indexer_client.create_or_update_data_source_connection(data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Index„ÅÆÂÆöÁæ©„ÇíË°å„ÅÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_client.delete_index(INDEX_NAME)\n",
    "\n",
    "fields = [\n",
    "    # „Ç≠„Éº\n",
    "    SearchField(\n",
    "        name=\"id\",\n",
    "        type=\"Edm.String\",\n",
    "        key=True,\n",
    "        filterable=True,\n",
    "        sortable=True,\n",
    "    ),    \n",
    "    SearchField(\n",
    "        name=\"raw_id\",\n",
    "        type=\"Edm.String\",\n",
    "        filterable=True,\n",
    "        sortable=True,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"title\", \n",
    "        type=\"Edm.String\", \n",
    "        searchable=True,\n",
    "        analyzer_name=LexicalAnalyzerName.JA_LUCENE,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"text\",\n",
    "        type=\"Edm.String\",\n",
    "        searchable=True,\n",
    "        analyzer_name=LexicalAnalyzerName.JA_LUCENE,\n",
    "    ),\n",
    "    SearchField(\n",
    "        name=\"text_vector\",\n",
    "        type=\"Collection(Edm.Single)\",\n",
    "        searchable=True,\n",
    "        stored=True,\n",
    "        vector_search_dimensions=DIM,\n",
    "        vector_search_profile_name=\"aoai-hnsw\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(name=\"hnsw\")\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"aoai-hnsw\",\n",
    "            algorithm_configuration_name=\"hnsw\",\n",
    "            vectorizer_name=\"aoai-vectorizer\",\n",
    "        ),\n",
    "    ],\n",
    "    # „ÇØ„Ç®„É™ÊôÇ„ÅÆËá™Âãï„Éô„ÇØ„Éà„É´Âåñ\n",
    "    vectorizers=[\n",
    "        AzureOpenAIVectorizer(\n",
    "            vectorizer_name=\"aoai-vectorizer\",\n",
    "            parameters=AzureOpenAIVectorizerParameters(\n",
    "                resource_url=AOAI_ENDPOINT,\n",
    "                deployment_name=AOAI_EMBEDDING_DEPLOYMENT,\n",
    "                model_name=AOAI_EMBEDDING_MODEL,\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "semantic_search = SemanticSearch(\n",
    "    default_configuration_name=\"semantic_config\",\n",
    "    configurations=[\n",
    "        SemanticConfiguration(\n",
    "            name=\"semantic_config\",\n",
    "            prioritized_fields=SemanticPrioritizedFields(\n",
    "                title_field=SemanticField(field_name=\"title\"),\n",
    "                content_fields=[SemanticField(field_name=\"text\")]\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=INDEX_NAME,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search,\n",
    "    semantic_search=semantic_search,\n",
    ")\n",
    "\n",
    "index_client.create_or_update_index(index)\n",
    "print(f\"Index '{INDEX_NAME}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "# skillset„ÅÆÂÆöÁæ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_skill = AzureOpenAIEmbeddingSkill(\n",
    "    description=\"Skill to generate embeddings via Azure OpenAI\",\n",
    "    context=\"/document\",\n",
    "    resource_url=AOAI_ENDPOINT,\n",
    "    deployment_name=AOAI_EMBEDDING_DEPLOYMENT,\n",
    "    model_name=AOAI_EMBEDDING_MODEL,\n",
    "    dimensions=DIM,\n",
    "    inputs=[\n",
    "        InputFieldMappingEntry(name=\"text\", source=\"/document/text\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")\n",
    "    ],\n",
    ")\n",
    "\n",
    "skillset = SearchIndexerSkillset(\n",
    "    name=SKILLSET_NAME,\n",
    "    skills=[embedding_skill],\n",
    "    description=\"JQaRA index-time embedding skillset\",\n",
    ")\n",
    "\n",
    "indexer_client.create_or_update_skillset(skillset)\n",
    "print(\"Skillset created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Indexer„ÅÆÂÆöÁæ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = SearchIndexer(\n",
    "    name=INDEXER_NAME,\n",
    "    data_source_name=DATA_SOURCE_NAME,\n",
    "    target_index_name=INDEX_NAME,\n",
    "    skillset_name=SKILLSET_NAME,  # „Çπ„Ç≠„É´„Çª„ÉÉ„Éà„ÇíÁ¥ê„Å•„Åë\n",
    "    # „Éâ„Ç≠„É•„É°„É≥„Éà -> „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ „ÅÆ„Éï„Ç£„Éº„É´„Éâ„Éû„ÉÉ„Éî„É≥„Ç∞\n",
    "    field_mappings=[\n",
    "        FieldMapping(source_field_name=\"id\", target_field_name=\"id\"),\n",
    "        FieldMapping(source_field_name=\"raw_id\", target_field_name=\"raw_id\"),\n",
    "        FieldMapping(source_field_name=\"title\", target_field_name=\"title\"),\n",
    "        FieldMapping(source_field_name=\"text\", target_field_name=\"text\"),\n",
    "    ],\n",
    "    # „Çπ„Ç≠„É´Âá∫Âäõ -> „Ç§„É≥„Éá„ÉÉ„ÇØ„Çπ „ÅÆ„Éï„Ç£„Éº„É´„Éâ„Éû„ÉÉ„Éî„É≥„Ç∞\n",
    "    output_field_mappings=[\n",
    "        FieldMapping(\n",
    "            source_field_name=\"/document/text_vector\",\n",
    "            target_field_name=\"text_vector\",\n",
    "        ),\n",
    "    ],\n",
    "    # „Ç§„É≥„Éá„ÇØ„Çµ„ÅÆ„Éë„É©„É°„Éº„Çø\n",
    "    parameters=IndexingParameters(\n",
    "        configuration={\n",
    "            \"parsingMode\": \"jsonLines\",  # 1 JSON = 1 „Éâ„Ç≠„É•„É°„É≥„Éà\n",
    "            \"failOnUnsupportedContentType\": False,  # Êú™ÂØæÂøúMIME„ÅßÂ§±Êïó„Åï„Åõ„Å™„ÅÑ\n",
    "        }\n",
    "    ),\n",
    ")\n",
    "indexer_client.create_or_update_indexer(indexer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# Indexing„ÇíÂÆüË°å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Indexer „ÇíÊâãÂãïÂÆüË°å\n",
    "try:\n",
    "    # indexer_client.reset_indexer(INDEXER_NAME)  # 1) Â§âÊõ¥ËøΩË∑°Ôºà„Éè„Ç§„Ç¶„Ç©„Éº„Çø„Éº„Éû„Éº„ÇØÔºâ„Çí„É™„Çª„ÉÉ„Éà\n",
    "    indexer_client.run_indexer(INDEXER_NAME)\n",
    "    print(f\"Run requested: {INDEXER_NAME}\")\n",
    "except HttpResponseError as e:\n",
    "    print(\"Run failed:\", e)\n",
    "    raise\n",
    "\n",
    "# 2) Á∞°Êòì„Éù„Éº„É™„É≥„Ç∞ÔºàÁä∂ÊÖã„Åå terminal „Å´„Å™„Çã„Åæ„ÅßÂæÖ„Å§Ôºâ\n",
    "terminal = {\"success\", \"transientFailure\", \"persistentFailure\", \"reset\"}\n",
    "for i in range(60):  # ÊúÄÂ§ß ~5ÂàÜÂæÖÊ©üÔºà5Áßí√ó60Ôºâ\n",
    "    st = indexer_client.get_indexer_status(INDEXER_NAME)\n",
    "    last = st.last_result\n",
    "    status = getattr(last, \"status\", None)\n",
    "    processed = getattr(last, \"items_processed\", None)\n",
    "    failed = getattr(last, \"items_failed\", None)\n",
    "    print(f\"[{i}] status={status} processed={processed} failed={failed}\")\n",
    "\n",
    "    if status in terminal:\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "# 3) ÁµêÊûú„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "if status != \"success\":\n",
    "    raise RuntimeError(\n",
    "        f\"Indexer did not succeed. status={status}, processed={processed}, failed={failed}\"\n",
    "    )\n",
    "print(\"Indexer run completed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Search Client„ÇíÂÆöÁæ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    index_name=INDEX_NAME,\n",
    "    credential=credential,\n",
    "    api_version=SEARCH_API_VERSION,\n",
    ")\n",
    "\n",
    "async_search_client = AsyncSearchClinet(\n",
    "    endpoint=SEARCH_ENDPOINT,\n",
    "    index_name=INDEX_NAME,\n",
    "    credential=credential,\n",
    "    api_version=SEARCH_API_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"ÊëÇÊ∞è„Åß„ÅØ„Éû„Ç§„Éä„Çπ273.15Â∫¶„Å´„ÅÇ„Åü„Çã„ÄÅÂÖ®„Å¶„ÅÆÂéüÂ≠ê„ÅÆÊåØÂãï„ÅåÂÅúÊ≠¢„Åô„ÇãÊúÄ„ÇÇ‰Ωé„ÅÑÊ∏©Â∫¶„Çí‰Ωï„Å®„ÅÑ„ÅÜ„Åß„Åó„Çá„ÅÜ?\"\n",
    "results = search_client.search(\n",
    "        search_text=query,\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name=\"semantic_config\",\n",
    "        query_caption=\"extractive\",\n",
    "        query_answer=\"extractive\",\n",
    "        query_answer_threshold=0.1,\n",
    "        query_answer_count=3,\n",
    "        query_rewrites=\"generative\",\n",
    "        query_rewrites_count=3,\n",
    "        query_language=\"ja-jp\",        \n",
    "        debug=\"queryRewrites\",\n",
    "        top=5,\n",
    "        select=[\"raw_id\", \"title\", \"text\"],\n",
    "    )\n",
    "\n",
    "def to_jsonable(x):\n",
    "    if hasattr(x, \"as_dict\"):\n",
    "        return x.as_dict()\n",
    "    if isinstance(x, list):\n",
    "        return [to_jsonable(v) for v in x]\n",
    "    if isinstance(x, dict):\n",
    "        return {k: to_jsonable(v) for k, v in x.items()}\n",
    "    return x\n",
    "\n",
    "docs = []\n",
    "for r in results:\n",
    "    d = (to_jsonable(dict(r)))\n",
    "    debug_info = r.get(\"@search.debugInfo\")\n",
    "    if debug_info:\n",
    "        d[\"@search.debugInfo\"] = to_jsonable(debug_info)\n",
    "    docs.append(d)\n",
    "\n",
    "print(json.dumps(docs, ensure_ascii=False, indent=2))\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def full_text_search(query: str, topk: int = 10):\n",
    "    results =  await async_search_client.search(\n",
    "        search_text=query,\n",
    "        query_type=QueryType.SIMPLE,  # „Åæ„Åü„ÅØ QueryType.SEMANTICÔºàsemanticË®≠ÂÆö„Åå„ÅÇ„ÇãÂ†¥ÂêàÔºâ\n",
    "        top=topk,\n",
    "        select=[\"raw_id\"],\n",
    "    )\n",
    "    return [r[\"raw_id\"] async for r in results]\n",
    "\n",
    "\n",
    "async def vector_search(query: str, topk: int = 10):\n",
    "    vq = VectorizableTextQuery(\n",
    "        text=query,\n",
    "        k_nearest_neighbors=topk,\n",
    "        fields=\"text_vector\",\n",
    "    )\n",
    "\n",
    "    results =  await async_search_client.search(\n",
    "        search_text=None, vector_queries=[vq], select=[\"raw_id\"]\n",
    "    )\n",
    "\n",
    "    return [r[\"raw_id\"]  async for r in results]\n",
    "\n",
    "\n",
    "async def hybrid_search(query: str, topk: int = 10):\n",
    "    vq = VectorizableTextQuery(\n",
    "        text=query,\n",
    "        k_nearest_neighbors=topk,\n",
    "        fields=\"text_vector\",\n",
    "    )\n",
    "\n",
    "    results = await async_search_client.search(\n",
    "        search_text=query,\n",
    "        vector_queries=[vq],\n",
    "        select=[\"raw_id\"],\n",
    "        top=topk,\n",
    "    )\n",
    "\n",
    "    return [r[\"raw_id\"]  async for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_client.delete_agent(KNOWLEDGE_AGENT_NAME)\n",
    "# index_client.delete_knowledge_source(KNOWLEDGE_SOURCE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "# Knowledge Source„ÅÆ‰ΩúÊàê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = SearchIndexKnowledgeSource(\n",
    "    name=KNOWLEDGE_SOURCE_NAME,\n",
    "    description=\"Knowledge source for Earth at night data\",\n",
    "    search_index_parameters=SearchIndexKnowledgeSourceParameters(\n",
    "        search_index_name=INDEX_NAME,\n",
    "        source_data_select=\"id,raw_id,title,text\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "index_client.create_or_update_knowledge_source(\n",
    "    knowledge_source=ks, api_version=SEARCH_API_VERSION\n",
    ")\n",
    "print(f\"Knowledge source '{KNOWLEDGE_SOURCE_NAME}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Knowledge Agent„ÅÆ‰ΩúÊàê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_params = AzureOpenAIVectorizerParameters(\n",
    "    resource_url=AOAI_ENDPOINT,\n",
    "    deployment_name=AOAI_GPT_DEPLOYMENT,\n",
    "    model_name=AOAI_GPT_MODEL,\n",
    ")\n",
    "\n",
    "output_cfg = KnowledgeAgentOutputConfiguration(\n",
    "    modality=KnowledgeAgentOutputConfigurationModality.ANSWER_SYNTHESIS,\n",
    "    include_activity=True,\n",
    ")\n",
    "\n",
    "agent = KnowledgeAgent(\n",
    "    name=KNOWLEDGE_AGENT_NAME,\n",
    "    models=[KnowledgeAgentAzureOpenAIModel(azure_open_ai_parameters=aoai_params)],\n",
    "    knowledge_sources=[\n",
    "        KnowledgeSourceReference(\n",
    "            name=KNOWLEDGE_SOURCE_NAME,\n",
    "            reranker_threshold=2.0,\n",
    "        )\n",
    "    ],\n",
    "    output_configuration=output_cfg,\n",
    ")\n",
    "\n",
    "index_client.create_or_update_agent(agent, api_version=SEARCH_API_VERSION)\n",
    "print(f\"Knowledge agent '{KNOWLEDGE_AGENT_NAME}' created or updated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "# KnoldegeAgentRetrievalClient„ÅÆ‰ΩúÊàê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_client = KnowledgeAgentRetrievalClient(\n",
    "    endpoint=SEARCH_ENDPOINT, \n",
    "    agent_name=KNOWLEDGE_AGENT_NAME, \n",
    "    credential=credential\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = []\n",
    "\n",
    "query_1 = \"\"\"    \n",
    "    „Ç¢„É°„É™„Ç´„Å®„É≠„Ç∑„Ç¢„ÅåÂØæÂ≥ô„Åô„Çã„Åì„Å®„Åã„Çâ„ÄåÁ±≥„É≠Êµ∑Â≥°„Äç„ÅÆÂà•Âêç„ÇÇ„ÅÇ„Çã„ÄÅ„Ç¢„É©„Çπ„Ç´„ÅÆ„Çπ„ÉØ„Éº„ÉâÂçäÂ≥∂„Å®„ÄÅÊù±„Ç∑„Éô„É™„Ç¢„ÅÆ„ÉÅ„É•„ÇØ„ÉÅÂçäÂ≥∂„Å®„ÅÆÈñì„Å´„ÅÇ„ÇãÊµ∑Â≥°„ÅØ‰Ωï„Åß„Åó„Çá„ÅÜ?\n",
    "    „Åæ„Åü„ÄÅ„Åù„ÅÆÊµ∑Â≥°„ÇíÊåü„Çì„ÅßÂçóÂåó„Å´‰ΩçÁΩÆ„Åô„Çã‰∫å„Å§„ÅÆÊµ∑„ÅØ‰Ωï„Åß„Åó„Çá„ÅÜ?\n",
    "    \"\"\"\n",
    "query_2 = \"\"\"\n",
    "    ÁõÆ„ÅÆÊÑõË≠∑„Éá„Éº„ÅØ‰ΩïÊúà‰ΩïÊó•„Åß„Åó„Çá„ÅÜ?„Åæ„Åü„ÄÅËÄ≥„ÅÆÊó•„ÅØ‰ΩïÊúà‰ΩïÊó•„Åß„Åó„Çá„ÅÜ?„Åù„ÅÆÁêÜÁî±„ÇÇÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ\n",
    "    When is the International Day of Nonviolence?\n",
    "    „Åï„Çâ„Å´„ÄÅ„Åù„Çå„Åû„Çå„ÅÆÊó•„Å´‰Ωï„Çí„Åô„Çå„Å∞ËâØ„ÅÑ„ÅãÊïô„Åà„Å¶„Åè„Å†„Åï„ÅÑ\n",
    "\"\"\"\n",
    "messages.append({\"role\": \"user\", \"content\": query_2})\n",
    "\n",
    "req = KnowledgeAgentRetrievalRequest(\n",
    "    messages=[\n",
    "        KnowledgeAgentMessage(\n",
    "            role=m[\"role\"],\n",
    "            content=[KnowledgeAgentMessageTextContent(text=m[\"content\"])],\n",
    "        )\n",
    "        for m in messages\n",
    "        if m[\"role\"] != \"system\"\n",
    "    ],\n",
    "    knowledge_source_params=[\n",
    "        SearchIndexKnowledgeSourceParams(\n",
    "            knowledge_source_name=KNOWLEDGE_SOURCE_NAME, kind=\"searchIndex\"\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "result = agent_client.retrieve(retrieval_request=req, api_version=SEARCH_API_VERSION)\n",
    "print(f\"Retrieved content from '{KNOWLEDGE_SOURCE_NAME}' successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Response\")\n",
    "print(textwrap.fill(result.response[0].content[0].text, width=120))\n",
    "\n",
    "print(\"Activity\")\n",
    "print(json.dumps([a.as_dict() for a in result.activity], indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"Results\")\n",
    "print(\n",
    "    json.dumps([r.as_dict() for r in result.references], indent=2, ensure_ascii=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "# Ê§úÁ¥¢Ë©ï‰æ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Iterable\n",
    "\n",
    "\n",
    "qid_to_query: Dict[str, str] = {}\n",
    "qrels: Dict[str, Dict[str, int]] = {}\n",
    "\n",
    "cnt = 0\n",
    "for rec in test_data:\n",
    "    cnt += 1\n",
    "    qid   = rec[\"q_id\"]\n",
    "    query = rec.get(\"question\")\n",
    "    docid = rec.get(\"id\")\n",
    "    rel   = int(rec.get(\"label\", 0))\n",
    "\n",
    "    if qid not in qid_to_query:\n",
    "        qid_to_query[qid] = query\n",
    "    qrels.setdefault(qid, {})[docid] = rel\n",
    "\n",
    "print(f\"Loaded {cnt} records\")\n",
    "print(f\"Unique queries: {len(qid_to_query)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_text_search(query: str, topk: int = 10):\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        query_type=QueryType.SIMPLE,  # „Åæ„Åü„ÅØ QueryType.SEMANTICÔºàsemanticË®≠ÂÆö„Åå„ÅÇ„ÇãÂ†¥ÂêàÔºâ\n",
    "        top=topk,\n",
    "        select=[\"raw_id\"],\n",
    "    )\n",
    "    ranked = []\n",
    "    for r in results:\n",
    "        ranked.append((r[\"raw_id\"], float(r.get(\"@search.score\", 0.0))))\n",
    "    return ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "run_dict = {}  # {qid: {docid: score}}\n",
    "for qid, query in tqdm(qid_to_query.items(), total=len(qid_to_query)):\n",
    "    ranked = full_text_search(\n",
    "        query=query,\n",
    "    )\n",
    "    run_dict[qid] = {docid: score for docid, score in ranked}\n",
    "\n",
    "len(run_dict), list(run_dict.keys())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_full_text_search(query: str, topk: int = 10) -> List[Tuple[str, float]]:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    results = await async_search_client.search(\n",
    "        search_text=query,\n",
    "        query_type=QueryType.SIMPLE,   # Semantic„Å´„Åó„Åü„ÅÑÂ†¥Âêà„ÅØ QueryType.SEMANTIC\n",
    "        top=topk,\n",
    "        select=[\"raw_id\"],             # ÂøÖË¶Å„Å´Âøú„Åò„Å¶„Éï„Ç£„Éº„É´„ÉâËøΩÂä†\n",
    "    )\n",
    "    ranked: List[Tuple[str, float]] = []\n",
    "    async for r in results:\n",
    "        docid = r.get(\"raw_id\")\n",
    "        score = float(r.get(\"@search.score\", 0.0))\n",
    "        if docid is not None:\n",
    "            ranked.append((docid, score))\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    return ranked, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_vector_search(query: str, topk: int = 10) -> List[Tuple[str, float]]:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    vq = VectorizableTextQuery(\n",
    "        text=query,\n",
    "        k_nearest_neighbors=topk,\n",
    "        fields=\"text_vector\",\n",
    "    )\n",
    "\n",
    "    results =  await async_search_client.search(\n",
    "        search_text=None, \n",
    "        vector_queries=[vq], \n",
    "        select=[\"raw_id\"]\n",
    "    )\n",
    "\n",
    "    ranked: List[Tuple[str, float]] = []\n",
    "    async for r in results:\n",
    "        docid = r.get(\"raw_id\")\n",
    "        score = float(r.get(\"@search.score\", 0.0))\n",
    "        if docid is not None:\n",
    "            ranked.append((docid, score))\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    return ranked, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_hybrid_search(query: str, topk: int = 10) -> List[Tuple[str, float]]:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    vq = VectorizableTextQuery(\n",
    "        text=query,\n",
    "        k_nearest_neighbors=topk,\n",
    "        fields=\"text_vector\",\n",
    "    )\n",
    "\n",
    "    results =  await async_search_client.search(\n",
    "        search_text=query, \n",
    "        vector_queries=[vq], \n",
    "        select=[\"raw_id\"]\n",
    "    )\n",
    "\n",
    "    ranked: List[Tuple[str, float]] = []\n",
    "    async for r in results:\n",
    "        docid = r.get(\"raw_id\")\n",
    "        score = float(r.get(\"@search.score\", 0.0))\n",
    "        if docid is not None:\n",
    "            ranked.append((docid, score))\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    return ranked, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_full_text_semantic_search(query: str, topk: int = 10) -> List[Tuple[str, float]]:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    results = await async_search_client.search(\n",
    "        search_text=query,\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name=\"semantic_config\",\n",
    "        top=topk,\n",
    "        select=[\"raw_id\"],             # ÂøÖË¶Å„Å´Âøú„Åò„Å¶„Éï„Ç£„Éº„É´„ÉâËøΩÂä†\n",
    "    )\n",
    "    ranked: List[Tuple[str, float]] = []\n",
    "    async for r in results:\n",
    "        docid = r.get(\"raw_id\")\n",
    "        score = float(r.get(\"@search.score\", 0.0))\n",
    "        if docid is not None:\n",
    "            ranked.append((docid, score))\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    return ranked, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_vector_semantic_search(query: str, topk: int = 10) -> List[Tuple[str, float]]:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    vq = VectorizableTextQuery(\n",
    "        text=query,\n",
    "        k_nearest_neighbors=topk,\n",
    "        fields=\"text_vector\",\n",
    "    )\n",
    "\n",
    "    results =  await async_search_client.search(\n",
    "        search_text=None,                 \n",
    "        vector_queries=[vq], \n",
    "        select=[\"raw_id\"],\n",
    "        semantic_query=query,\n",
    "        semantic_configuration_name=\"semantic_config\",\n",
    "    )\n",
    "\n",
    "    ranked: List[Tuple[str, float]] = []\n",
    "    async for r in results:\n",
    "        docid = r.get(\"raw_id\")\n",
    "        score = float(r.get(\"@search.score\", 0.0))\n",
    "        if docid is not None:\n",
    "            ranked.append((docid, score))\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    return ranked, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_hybrid_semantic_search(query: str, topk: int = 10) -> List[Tuple[str, float]]:\n",
    "    start = time.perf_counter()\n",
    "\n",
    "    vq = VectorizableTextQuery(\n",
    "        text=query,\n",
    "        k_nearest_neighbors=topk,\n",
    "        fields=\"text_vector\",\n",
    "    )\n",
    "\n",
    "    results =  await async_search_client.search(\n",
    "        search_text=query, \n",
    "        vector_queries=[vq], \n",
    "        semantic_query=query,\n",
    "        semantic_configuration_name=\"semantic_config\",\n",
    "        select=[\"raw_id\"]\n",
    "    )\n",
    "\n",
    "    ranked: List[Tuple[str, float]] = []\n",
    "    async for r in results:\n",
    "        docid = r.get(\"raw_id\")\n",
    "        score = float(r.get(\"@search.score\", 0.0))\n",
    "        if docid is not None:\n",
    "            ranked.append((docid, score))\n",
    "    \n",
    "    elapsed = time.perf_counter() - start\n",
    "    return ranked, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Awaitable, List, Tuple, Dict\n",
    "\n",
    "async def build_run_dict_async(\n",
    "        search_fn: Callable[[str, int], Awaitable[List[Tuple[str, float]]]],\n",
    "        qid_to_query: Dict[str, str]\n",
    "    ) -> Dict[str, Dict[str, float]]:\n",
    "    CONCURRENCY = 10\n",
    "    sem = asyncio.Semaphore(CONCURRENCY)    \n",
    "    run_dict: Dict[str, Dict[str, float]] = {}\n",
    "    latencies = []\n",
    "\n",
    "    async def _one(qid: str, q: str):\n",
    "        async with sem:\n",
    "            ranked, elapsed = await search_fn(q)\n",
    "            return qid, ranked, elapsed\n",
    "\n",
    "    tasks = [_one(qid, q) for qid, q in qid_to_query.items()]\n",
    "    \n",
    "    for coro in tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "        qid, ranked, elapsed = await coro\n",
    "        run_dict[qid] = {docid: score for docid, score in ranked}\n",
    "        latencies.append(elapsed)\n",
    "    \n",
    "    return run_dict, latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext_search_run_dict, fulltext_search_latencies = await build_run_dict_async(async_full_text_search, qid_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltext_semantic_search_run_dict, fulltext_semantic_search_latencies = await build_run_dict_async(async_full_text_semantic_search, qid_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_search_run_dict, vector_search_latencies = await build_run_dict_async(async_vector_search, qid_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_semantic_search_run_dict, vector_semantic_search_latencies = await build_run_dict_async(async_vector_semantic_search, qid_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_search_run_dict, hybrid_search_latencies = await build_run_dict_async(async_hybrid_search, qid_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_semantic_search_run_dict, hybrid_semantic_search_latencies = await build_run_dict_async(async_hybrid_semantic_search, qid_to_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = await async_vector_search(query=\"ÊëÇÊ∞è„Åß„ÅØ„Éû„Ç§„Éä„Çπ273.15Â∫¶„Å´„ÅÇ„Åü„Çã\")\n",
    "# result\n",
    "\n",
    "query = \"ÊëÇÊ∞è„Åß„ÅØ„Éû„Ç§„Éä„Çπ273.15Â∫¶„Å´„ÅÇ„Åü„Çã\"\n",
    "vq = VectorizableTextQuery(\n",
    "    text=query,\n",
    "    k_nearest_neighbors=10,\n",
    "    fields=\"text_vector\",\n",
    ")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=None,                 \n",
    "    vector_queries=[vq], \n",
    "    select=[\"raw_id\"],\n",
    "    semantic_query=query,\n",
    "    semantic_configuration_name=\"semantic_config\",\n",
    ")\n",
    "\n",
    "def to_jsonable(x):\n",
    "    if hasattr(x, \"as_dict\"):\n",
    "        return x.as_dict()\n",
    "    if isinstance(x, list):\n",
    "        return [to_jsonable(v) for v in x]\n",
    "    if isinstance(x, dict):\n",
    "        return {k: to_jsonable(v) for k, v in x.items()}\n",
    "    return x\n",
    "\n",
    "docs = []\n",
    "for r in results:\n",
    "    d = (to_jsonable(dict(r)))\n",
    "    debug_info = r.get(\"@search.debugInfo\")\n",
    "    if debug_info:\n",
    "        d[\"@search.debugInfo\"] = to_jsonable(debug_info)\n",
    "    docs.append(d)\n",
    "\n",
    "print(json.dumps(docs, ensure_ascii=False, indent=2))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ranx import Qrels, Run, evaluate\n",
    "\n",
    "def evaluate_run_dict(run_dict: Dict[str, Dict[str, float]], qrels: Dict[str, Dict[str, int]]):\n",
    "    qrels_ranx = Qrels(qrels)\n",
    "    run_ranx   = Run(run_dict)\n",
    "\n",
    "    metrics = [\n",
    "        \"ndcg@1\", \"ndcg@3\", \"ndcg@5\", \"ndcg@10\",\n",
    "        \"map\", \"mrr\", \"precision@10\", \"recall@10\", \"recall@100\",\n",
    "    ]\n",
    "\n",
    "    scores = evaluate(qrels_ranx, run_ranx, metrics=metrics)\n",
    "    for m in metrics:\n",
    "        print(f\"{m:>12}: {scores[m]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_latency_stats(latencies: List[float]):\n",
    "    l = np.array(latencies)\n",
    "\n",
    "    print(f\"Count    : {len(l)}\")\n",
    "    print(f\"Mean     : {l.mean():.4f} sec\")\n",
    "    print(f\"Median   : {np.median(l):.4f} sec\")\n",
    "    print(f\"p90      : {np.percentile(l,90):.4f} sec\")\n",
    "    print(f\"p95      : {np.percentile(l,95):.4f} sec\")\n",
    "    print(f\"p99      : {np.percentile(l,99):.4f} sec\")\n",
    "    print(f\"Min/Max  : {l.min():.4f} / {l.max():.4f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_run_dict(fulltext_search_run_dict, qrels)\n",
    "print_latency_stats(fulltext_search_latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_run_dict(fulltext_semantic_search_run_dict, qrels)\n",
    "print_latency_stats(fulltext_semantic_search_latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_run_dict(vector_search_run_dict, qrels)\n",
    "print_latency_stats(vector_search_latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_run_dict(vector_semantic_search_run_dict, qrels)\n",
    "print_latency_stats(vector_semantic_search_latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_run_dict(hybrid_search_run_dict, qrels)\n",
    "print_latency_stats(hybrid_search_latencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "# Ragas„Å´„Çà„ÇãË©ï‰æ°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ai-search-agentic-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
